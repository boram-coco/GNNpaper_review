[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GNNpaper_review",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n(연구&보람) 결과시각화 – Experiment 1\n\n\n \n\n\n\n\nApr 11, 2024\n\n\ngraft\n\n\n김보람 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-04-11-결과시각화-- 실험1.out.html",
    "href": "posts/2024-04-11-결과시각화-- 실험1.out.html",
    "title": "(연구&보람) 결과시각화 – Experiment 1",
    "section": "",
    "text": "(연구&보람) 결과시각화 – Experiment 1\n김보람\n2024-04-03\n\nimport pandas as pd\nimport numpy as np\n#import sklearn\nimport pickle \nimport time \nimport datetime\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\ndf = pd.read_csv('./240414_meged.csv')\ndf = df[['L2' not in l and 'L1' not in l for l in df.model]]\n#df['diff'] = abs(merged_df['train_frate'] - merged_df['test_frate'])\ndf = df[(df.test_frate &lt;= 0.005) & (0.009 &lt; df.train_frate) & (df.train_frate &lt; 0.51)]\n\n\ndf\n\n\n\n\n\n\n\n\nmodel\ntime\nacc\npre\nrec\nf1\nauc\ngraph_based\nmethod\nthrow_rate\ntrain_size\ntrain_cols\ntrain_frate\ntest_size\ntest_frate\nhyper_params\ntheta\ngamma\n\n\n\n\n0\nECOD\n0.003704\n0.591404\n0.003553\n0.843750\n0.007076\n0.717359\nFalse\npyod\n0.097074\n10010\n['amt']\n0.450350\n37088\n0.001726\nNaN\nNaN\nNaN\n\n\n1\nGMM\n0.082634\n0.692003\n0.003410\n0.609375\n0.006782\n0.650760\nFalse\npyod\n0.097074\n10010\n['amt']\n0.450350\n37088\n0.001726\nNaN\nNaN\nNaN\n\n\n2\nHBOS\n0.002123\n0.936368\n0.020868\n0.781250\n0.040650\n0.858943\nFalse\npyod\n0.097074\n10010\n['amt']\n0.450350\n37088\n0.001726\nNaN\nNaN\nNaN\n\n\n3\nIForest\n0.144727\n0.815358\n0.007263\n0.781250\n0.014393\n0.798334\nFalse\npyod\n0.097074\n10010\n['amt']\n0.450350\n37088\n0.001726\nNaN\nNaN\nNaN\n\n\n4\nINNE\n0.326223\n0.766636\n0.005070\n0.687500\n0.010065\n0.727136\nFalse\npyod\n0.097074\n10010\n['amt']\n0.450350\n37088\n0.001726\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13522\nExtraTreesEntr\nNaN\n0.994760\n0.122807\n0.241379\n0.162791\n0.763820\nFalse\nAutogluon\n0.008901\n500499\n['amt']\n0.009087\n13741\n0.002110\nNaN\nNaN\nNaN\n\n\n13523\nNeuralNetFastAI\nNaN\n0.997890\n0.000000\n0.000000\n0.000000\n0.917705\nFalse\nAutogluon\n0.008901\n500499\n['amt']\n0.009087\n13741\n0.002110\nNaN\nNaN\nNaN\n\n\n13524\nXGBoost\nNaN\n0.996580\n0.178571\n0.172414\n0.175439\n0.939455\nFalse\nAutogluon\n0.008901\n500499\n['amt']\n0.009087\n13741\n0.002110\nNaN\nNaN\nNaN\n\n\n13525\nNeuralNetTorch\nNaN\n0.997162\n0.187500\n0.103448\n0.133333\n0.941711\nFalse\nAutogluon\n0.008901\n500499\n['amt']\n0.009087\n13741\n0.002110\nNaN\nNaN\nNaN\n\n\n13526\nLightGBMLarge\nNaN\n0.997890\n0.000000\n0.000000\n0.000000\n0.944964\nFalse\nAutogluon\n0.008901\n500499\n['amt']\n0.009087\n13741\n0.002110\nNaN\nNaN\nNaN\n\n\n\n\n6405 rows × 18 columns\n\n\n\n\nfig = px.scatter(\n    df,\n    x='train_frate',y='auc',\n    color='method',\n    hover_data='f1',\n    opacity=0.2,\n    #---#\n    width = 750,\n    height = 800  \n)\nfig.data[3]['marker']['opacity'] = 0.7\nfig.data[3]['marker']['size'] = 9\nfig\n\nValueError: Value of 'hover_data_0' is not the name of a column in 'data_frame'. Expected one of ['model', 'time', 'acc', 'pre', 'rec', 'f1', 'auc', 'graph_based', 'method', 'throw_rate', 'train_size', 'train_cols', 'train_frate', 'test_size', 'test_frate', 'hyper_params', 'theta', 'gamma'] but received: f\n\n\n\nfig\n\n                                                \n\n\n\ndf2 = pd.read_csv('./240414_meged.csv')\ndf2 = df[['L2' not in l and 'L1' not in l for l in df.model]]\n#df['diff'] = abs(merged_df['train_frate'] - merged_df['test_frate'])\ndf3 = df2[(df2.test_frate &lt;= 0.005) & (df2.train_frate &lt;= 0.1)]\n\n\ndf3 = df3.drop_duplicates()\n\n\nfig2 = px.scatter(\n    df3,\n    x='train_frate',y='f1',\n    color='method',\n#    hover_data='model',\n    opacity=0.2,\n    #---#\n    width = 750,\n    height = 800  \n)\nfig2"
  },
  {
    "objectID": "posts/231111.html",
    "href": "posts/231111.html",
    "title": "graft",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\nimport pickle\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n# gnn\nimport torch\nimport torch.nn.functional as F\nimport torch_geometric\nfrom torch_geometric.nn import GCNConv\n\nimport graft\n\n\n%run ~/Dropbox/GNNpaper/posts/function_proposed_gcn.py\n\n\nwith open('./fraudTrain.pkl', 'rb') as file:\n    fraudTrain = pickle.load(file)    \n\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef compute_time_difference(group):\n    n = len(group)\n    result = []\n    for i in range(n):\n        for j in range(n):\n            time_difference = abs(group.iloc[i].trans_date_trans_time.value - group.iloc[j].trans_date_trans_time.value)\n            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n    return result\n\ndef mask(df):\n    df_tr,df_test = sklearn.model_selection.train_test_split(df, random_state=42)\n    N = len(df)\n    train_mask = [i in df_tr.index for i in range(N)]\n    test_mask = [i in df_test.index for i in range(N)]\n    train_mask = np.array(train_mask)\n    test_mask = np.array(test_mask)\n    return train_mask, test_mask\n\ndef edge_index_selected(edge_index):\n    theta = edge_index[:,2].mean()\n    edge_index[:,2] = (np.exp(-edge_index[:,2]/theta) != 1)*(np.exp(-edge_index[:,2]/theta))\n    edge_index = edge_index.tolist()\n    mean_ = np.array(edge_index)[:,2].mean()\n    selected_edges = [(int(row[0]), int(row[1])) for row in edge_index if row[2] &gt; mean_]\n    edge_index_selected = torch.tensor(selected_edges, dtype=torch.long).t()\n    return edge_index_selected\n\n\n\n\n\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf50 = down_sample_textbook(df02)\ndf50 = df50.reset_index()\ndf50.shape\n\n(12012, 23)\n\n\n\n\n\n\nmask(df50)\n\ntrain_mask, test_mask = mask(df50)"
  },
  {
    "objectID": "posts/231111.html#데이터정리",
    "href": "posts/231111.html#데이터정리",
    "title": "graft",
    "section": "",
    "text": "_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf50 = down_sample_textbook(df02)\ndf50 = df50.reset_index()\ndf50.shape\n\n(12012, 23)\n\n\n\n\n\n\nmask(df50)\n\ntrain_mask, test_mask = mask(df50)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]