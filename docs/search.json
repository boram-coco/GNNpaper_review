[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GNNpaper_review",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n(연구&보람) 결과시각화 – Experiment 1\n\n\n \n\n\n\n\nApr 11, 2024\n\n\ngraft\n\n\n김보람 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-04-11-결과시각화-- 실험1.out.html",
    "href": "posts/2024-04-11-결과시각화-- 실험1.out.html",
    "title": "(연구&보람) 결과시각화 – Experiment 1",
    "section": "",
    "text": "(연구&보람) 결과시각화 – Experiment 1\n김보람\n2024-04-03\n\nimport pandas as pd\nimport numpy as np\n#import sklearn\nimport pickle \nimport time \nimport datetime\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\ndf = pd.read_csv('./240404_meged.csv')\ndf = df[['L2' not in l and 'L1' not in l for l in df.model]]\n#df['diff'] = abs(merged_df['train_frate'] - merged_df['test_frate'])\ndf = df[(df.test_frate &lt;= 0.005) & (0.009 &lt; df.train_frate) & (df.train_frate &lt; 0.51)]\n\n\nfig = px.scatter(\n    df,\n    x='train_frate',y='auc',\n    color='method',\n    hover_data='model',\n    opacity=0.2,\n    #---#\n    width = 750,\n    height = 800  \n)\nfig.data[3]['marker']['opacity'] = 0.7\nfig.data[3]['marker']['size'] = 9\nfig\n\nValueError: Value of 'hover_data_0' is not the name of a column in 'data_frame'. Expected one of ['model', 'time', 'acc', 'pre', 'rec', 'f1', 'auc', 'graph_based', 'method', 'throw_rate', 'train_size', 'train_cols', 'train_frate', 'test_size', 'test_frate', 'hyper_params', 'theta', 'gamma'] but received: m"
  },
  {
    "objectID": "posts/231111.html",
    "href": "posts/231111.html",
    "title": "graft",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\nimport pickle\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n# gnn\nimport torch\nimport torch.nn.functional as F\nimport torch_geometric\nfrom torch_geometric.nn import GCNConv\n\nimport graft\n\n\n%run ~/Dropbox/GNNpaper/posts/function_proposed_gcn.py\n\n\nwith open('./fraudTrain.pkl', 'rb') as file:\n    fraudTrain = pickle.load(file)    \n\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef compute_time_difference(group):\n    n = len(group)\n    result = []\n    for i in range(n):\n        for j in range(n):\n            time_difference = abs(group.iloc[i].trans_date_trans_time.value - group.iloc[j].trans_date_trans_time.value)\n            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n    return result\n\ndef mask(df):\n    df_tr,df_test = sklearn.model_selection.train_test_split(df, random_state=42)\n    N = len(df)\n    train_mask = [i in df_tr.index for i in range(N)]\n    test_mask = [i in df_test.index for i in range(N)]\n    train_mask = np.array(train_mask)\n    test_mask = np.array(test_mask)\n    return train_mask, test_mask\n\ndef edge_index_selected(edge_index):\n    theta = edge_index[:,2].mean()\n    edge_index[:,2] = (np.exp(-edge_index[:,2]/theta) != 1)*(np.exp(-edge_index[:,2]/theta))\n    edge_index = edge_index.tolist()\n    mean_ = np.array(edge_index)[:,2].mean()\n    selected_edges = [(int(row[0]), int(row[1])) for row in edge_index if row[2] &gt; mean_]\n    edge_index_selected = torch.tensor(selected_edges, dtype=torch.long).t()\n    return edge_index_selected\n\n\n\n\n\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf50 = down_sample_textbook(df02)\ndf50 = df50.reset_index()\ndf50.shape\n\n(12012, 23)\n\n\n\n\n\n\nmask(df50)\n\ntrain_mask, test_mask = mask(df50)"
  },
  {
    "objectID": "posts/231111.html#데이터정리",
    "href": "posts/231111.html#데이터정리",
    "title": "graft",
    "section": "",
    "text": "_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf50 = down_sample_textbook(df02)\ndf50 = df50.reset_index()\ndf50.shape\n\n(12012, 23)\n\n\n\n\n\n\nmask(df50)\n\ntrain_mask, test_mask = mask(df50)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]